# Expected Deliverables:

1. The complete, runnable Python code implementation (pasted as text) used for data preprocessing, model training, and SHAP visualization generation.

from sklearn.datasets import fetch_openml
import pandas as pd   #reading CSV/Excel, dataframes, cleaning
import numpy as np   #numerical operations and arrays.
import matplotlib.pyplot as plt  #Basic plotting
import seaborn as sns   #Enhanced statistical visualization
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split,  GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.ensemble import RandomForestClassifier
import shap
data = fetch_openml(name="Taiwanese_Bankruptcy_Prediction", version=1, as_frame=True)
df = data.frame
#Encode target label 'Bankrupt' (Yes=1, No=0)
label_encoder = LabelEncoder()
df['Bankrupt'] = label_encoder.fit_transform(df['Bankrupt'])
X = df.drop('Bankrupt', axis=1)
y = df['Bankrupt']
print("\n After encoded:")
print(X)
print(y)
#Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print("\n Scaled Data:")
print(X_scaled)
#Random Forest Training + Hyperparameter Optimization (Task 1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
# Build Random Forest Model
param_grid = {
    "n_estimators": [200, 400],
    "max_depth": [10, 20, None],
    "min_samples_split": [2, 5],
    "min_samples_leaf": [1, 2],
    "class_weight": ["balanced"]
}
rf = RandomForestClassifier(random_state=42)
grid = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    scoring="f1",
    cv=3,
    n_jobs=-1,
    verbose=1
)
grid.fit(X_train, y_train)
best_rf = grid.best_estimator_
print("Best Parameters: \n", grid.best_params_)
y_pred = best_rf.predict(X_test)
y_prob = best_rf.predict_proba(X_test)[:, 1]
print("\nCONFUSION MATRIX:\n", confusion_matrix(y_test, y_pred))
print("\nCLASSIFICATION REPORT:\n", classification_report(y_test, y_pred))
print("\nAUC SCORE:", roc_auc_score(y_test, y_prob))
#Global SHAP Feature Importance (Task 2)
shap.initjs()
explainer = shap.TreeExplainer(best_rf)
shap_values = explainer.shap_values(X_test)
#SHAP summary plot
shap.summary_plot(shap_values[:, :, 1], X_test)
#SHAP bar plot
shap.summary_plot(shap_values[:, :, 1], X_test, plot_type="bar")
#Local SHAP Explanations for 3 Case Examples (Task 3)
case_indices = [
    np.argmax(shap_values[:, :, 1].sum(axis=1)),  # highest risk
    np.argmin(shap_values[:, :, 1].sum(axis=1)),  # lowest risk
    np.random.randint(0, len(X_test))       # random
]
for i, idx in enumerate(case_indices):
    print(f"\nCASE {i+1} â€” index {idx}")
    shap.force_plot(
        explainer.expected_value[1],
        shap_values[:, :, 1][idx],
        X_test.iloc[idx, :],
        matplotlib=True
    )
top_features = np.argsort(np.abs(shap_values[:, :, 1]).mean(axis=0))[-3:]
for f in top_features:
    shap.dependence_plot(f, shap_values[:, :, 1], X_test)
#Compare RF Feature Importance vs SHAP Importance (Task 4)
rf_importance = pd.DataFrame({
    "feature": X.columns,
    "rf_importance": best_rf.feature_importances_
}).sort_values("rf_importance", ascending=False)
shap_importance = pd.DataFrame({
    "feature": X.columns,
    "shap_importance": np.abs(shap_values[:, :, 1]).mean(axis=0)
}).sort_values("shap_importance", ascending=False)
print("\nRandom Forest Importance:\n", rf_importance.head(10))
print("\nSHAP Importance:\n", shap_importance.head(10))
